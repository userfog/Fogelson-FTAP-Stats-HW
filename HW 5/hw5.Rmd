---
title: "FTAP Homework 5"
author: "Zachary Fogelson"
date: "July 16, 2015"
output: html_document
---

```{r, include = F}
library(gdata)
library(plyr)
library(knitr)
```

# Problem 1

**a** 


$$s_{fit} = s\sqrt(\frac{1}{n}+\frac{(X_f - \bar{X})}{(n-1)s_X^2})$$

$$Sd = 20.76$$
$$\bar{X} = 11.04966$$
$$n = 5336$$
$$S_x^2 = 7.817402$$

$$s_{fit} = 20.76 * \sqrt(\frac{1}{5336} + \frac{(10 - 11.0496)^2}{5335 * 7.817402})$$

$$s_{fit} = 0.303531$$

$$CI = (11.65672, 12.74613)$$


```{r}
wgs <- read.xls(xls = "censuswage.xls")
lm.out <- lm(Wage ~ School, wgs)
predict(lm.out,data.frame(School=c(10)), interval = "confidence")
```


**b**

```{r}
plot(Wage ~ School, wgs[wgs$School >= 10, ], ylim=c(-100, 700))
pred.int <- predict(lm.out, newdata = data.frame(School=c(10:17)), interval = "predict")
conf.int <- predict(lm.out, newdata = data.frame(School=c(10:17)), interval = "confidence")
lines(c(10:17), pred.int[,1], col="red", lwd = 2)
lines(c(10:17), pred.int[,2], col="blue",  type="l", lty=2, lwd = 2)
lines(c(10:17), pred.int[,3], col="blue",  type="l", lty=2, lwd = 2)
lines(c(10:17), conf.int[,2], col="green",  type="l", lty=2, lwd = 2)
lines(c(10:17), conf.int[,3], col="green",  type="l", lty=2, lwd = 2)
```

### Problem 2

```{r}
ceo <- read.xls(xls = "ceosalary.xls")
lm.out <- lm(salary ~ comten + ceoten + sales, ceo)
print(lm.out)  # Point Estimates
summary(lm.out)$coefficients[,"Std. Error"] # Std Errors (You can also see this from sqrt(diag(vcov(lm.out))))
confint(lm.out)  # Confidence intervals
summary(lm.out)$coefficients[,"Pr(>|t|)"]
```

**a**

Because the confidence interval for the slope coefficient of company tenure on ceo salary includes 0. We could hypothesise that company tenure is unrelated to ceo salary. However, company tenure is probably highly correlated with ceo tenure. Therefore, the large covariance between the two variables may be causing the counter intuative relationship between company tenure and salary.

**b**

Because the confidence interval for sales does not include 0 and because the p-value for the statistical significance for sales as a determininent of sales is far below the 99% confidence level we can be confident that theory two is incorrect.


### Probelm 3

```{r}
redrum <- read.xls(xls = "murder.xls")
plot(redrum)
```

**a** 
```{r}
redrum$CapPun <- as.numeric(redrum$exec > 0)
lm.out <- lm(mrdrate ~ unemp + CapPun, redrum)
lm.out
```

**b**

The coefficient on the capital punishment variable means that for a given level of unemployment, whether a community has capital punishment or not is associated with 1.753% higher murder rate.

**c**

```{r}
summary(lm.out)
```

Null Hypothesis:
$H_0: \beta_{2} = 0$

Alternative:
$H_1: \beta_{2} \ne 0$


Because the p-value for $\beta_2$ is >5% we fail to reject the null hypothesis that whether or not a community has capital punishment influences the murder rate.

Controlling for the effects of unemployment, the presence of capital punishment we cannot say that capital punishment is correlated to the murder rate.

**d**

```{r}
predict(lm.out, newdata = data.frame(unemp=c(6,6), CapPun=c(1,0)), interval = "predict")
```

These intervals are very large! Both intervals include 0 also both intervals include values with are both \>2x and \<x\/2 the fit (spot estimate) value.

**e**

```{r}
plot(mrdrate ~ unemp, redrum)
dcUnemp <- redrum[redrum$state == 9,]$unemp
dcMrdrate <- redrum[redrum$state == 9,]$mrdrate
text(x = dcUnemp, y = dcMrdrate, labels = c("DC87 (6.3, 36.2)", "DC90 (6.6, 77.8)", "DC93 (8.5, 78.5)"), cex = .7, pos = 1)
```

```{r}
redrumNoDC <- redrum[redrum$state != 9,]
lm.out <- lm(mrdrate ~ unemp + CapPun, redrumNoDC)
lm.out
```

Based on the new regression which excludes Washington D.C. for an given level of unemployment, whether or not a state has capital punishment is associated with a 3.6% higher murder rate.

```{r}
summary(lm.out)
```

Null Hypothesis:
$H_0: \beta_{2} = 0$

Alternative:
$H_1: \beta_{2} \ne 0$

Because the p-value for the $\beta_2$ coefficient is less than .001% we are able to be more than 99% confident in rejecting the null hypothesis.

***Discussion:***

We know that the t-statistic for multiple varaiable regressions depend the standard error of the coefficient we are examining.

$$t = \frac{b_j - \beta_j}{s_{b_j}}$$

Furthermore, we know that the standard error for a given $\beta$ depends on $\sigma^2$.

(https://stats.stackexchange.com/questions/44838/how-are-the-standard-errors-of-coefficients-calculated-in-a-regression)

Therefore, by removing the observations for DC which have extremely large residuals we have dramatically reduced the observed variance in $\sigma^2$ and, we manufacture much smaller t-values.


### Problem 4

```{r}
rank <- read.xls(xls = "rank.xls")
plot(rank)
```

**a**

```{r}
lm.out <- lm(salary ~ cost, rank)
plot(salary ~ cost, rank)
abline(lm.out, col = "red")
summary(lm.out) 

cor(rank$salary, rank$cost)
```

The correlation between cost and entry salary is $\approx$ .314.

**b**

Based on the scatter plot of salary versus cost shown above, business school costs are clearly left skewed. There are a large number of schools whose tuition are between 35 and 40 thousand dollars a semester but there individual schools which charge as little as 15 thousand a semester.

**c**
rent
According to the regression, for each additional dollar we spend to go to business school we will make an addition $.32 for our future entry salary. Based on the slope estimate alone I don't believe that anything can be concluded, we do not know whether the slope is significant. It is possible that we would get this slope even through there is not a linear relationship between cost and entry salary.

**d**

Yes, I believe we need to be very careful in interpretting these results because the scatter plot looks highly non-linear.


